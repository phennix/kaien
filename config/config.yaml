# config/config.yaml

# LLM Provider Configuration
llm:
  provider: ollama
  host: "http://192.168.0.111:11434"

# models on server:
#  NAME                                                               ID              SIZE      MODIFIED
#  gpt-oss:20b                                                        17052f91a42e    13 GB     3 days ago
#  qwen2.5-coder:32b                                                  b92d6a0bd47e    19 GB     5 weeks ago
#  qwen3:8b                                                           500a1f067a9f    5.2 GB    5 weeks ago
#  qwen2.5-coder:7b                                                   dae161e27b0e    4.7 GB    5 weeks ago
#  qwen3:14b                                                          bdbd181c33f2    9.3 GB    5 weeks ago
#  qwen2.5-coder:14b                                                  9ec8897f747e    9.0 GB    5 weeks ago
#  gemma3:27b                                                         a418f5838eaf    17 GB     5 weeks ago
#  gemma3:4b                                                          a2af6cc3eb7f    3.3 GB    5 weeks ago
#  gemma3:12b                                                         f4031aab637d    8.1 GB    5 weeks ago
#  deepseek-r1:14b                                                    c333b7232bdb    9.0 GB    5 weeks ago
#  deepseek-r1:8b                                                     6995872bfe4c    5.2 GB    5 weeks ago
#  deepseek-coder:1.3b                                                3ddd2d3fc8d2    776 MB    5 weeks ago
#  deepseek-coder:6.7b                                                ce298d984115    3.8 GB    5 weeks ago
#  deepseek-coder:33b                                                 acec7c0b0fd9    18 GB     5 weeks ago
#  deepseek-r1:32b


  model: "gpt-oss:20b" # Default model to use
  request_timeout: 120

# Agent Configuration
agent:
  max_loop_iterations: 25
  history_pruning_threshold: 10 # Number of turns to keep in active memory

# Registered MCP Extensions (The service discovery mechanism)
extensions:
  - name: "system"
    address: "localhost:50051"
    enabled: true
  - name: "developer"
    address: "localhost:50052"
    enabled: true
  - name: "memory"
    address: "localhost:50053"
    enabled: false # Can be enabled later
  - name: "anus_sandbox"
    address: "localhost:50054"
    enabled: false
  - name: "document_qa"
    address: "localhost:50055"
    enabled: false

# Logging Configuration
logging:
  level: "INFO"
  file: "/var/log/kaien/agent.log"


# Agent's Core Directives and Personality
system_prompt: |
  You are Kaien, a highly intelligent and autonomous AI agent.
  Your purpose is to assist the user by executing tasks accurately and efficiently.
  
  **Communication Style:**
  - Be direct, concise, and professional.
  - Announce the action you are about to take before executing it.
  - Report the outcome of the action clearly.

  **Limitations and Rules:**
  - You must only use the tools provided to you. Do not invent tools.
  - You must operate within the designated file system boundaries.
  - Your goal is to complete the user's request, not to engage in open-ended conversation.
  - Respond with a tool call in a structured JSON format when a tool is required. Example: {"tool": "system.Ping", "arguments": {}}